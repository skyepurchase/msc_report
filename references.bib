@article{steering-taxonomy,
  title={Taxonomy, opportunities, and challenges of representation engineering for large language models},
  author={Wehner, Jan and Abdelnabi, Sahar and Tan, Daniel and Krueger, David and Fritz, Mario},
  journal={arXiv preprint arXiv:2502.19649},
  year={2025}
}

@article{steering-theory,
  title={A Unified Understanding and Evaluation of Steering Methods},
  author={Im, Shawn and Li, Yixuan},
  journal={arXiv preprint arXiv:2502.02716},
  year={2025}
}

@inproceedings{non-linear-features,
  title={Not All Language Model Features Are Linear},
  author={Engels, Joshua and Liao, Isaac and Michaud, Eric J and Gurnee, Wes and Tegmark, Max},
  booktitle={2025 Joint Mathematics Meetings (JMM 2025)},
  organization={AMS},
  year={2025}
}

@article{sea,
  title={Spectral editing of activations for large language model alignment},
  author={Qiu, Yifu and Zhao, Zheng and Ziser, Yftah and Korhonen, Anna and Ponti, Edoardo Maria and Cohen, Shay},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={56958--56987},
  year={2024}
}

@inproceedings{mimic,
  title={Representation surgery: theory and practice of affine steering},
  author={Singh, Shashwat and Ravfogel, Shauli and Herzig, Jonathan and Aharoni, Roee and Cotterell, Ryan and Kumaraguru, Ponnurangam},
  booktitle={Proceedings of the 41st International Conference on Machine Learning},
  pages={45663--45680},
  year={2024}
}

@inproceedings{function-vectors,
  title={Function Vectors in Large Language Models},
  author={Todd, Eric and Li, Millicent and Sharma, Arnab Sen and Mueller, Aaron and Wallace, Byron C and Bau, David},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@inproceedings{conceptors,
  title={Steering Large Language Models using Conceptors: Improving Addition-Based Activation Engineering},
  author={Postmus, Joris and Abreu, Steven},
  booktitle={MINT: Foundation Model Interventions},
  year={2024}
}

@article{steerability,
  title={Analyzing the Generalization and Reliability of Steering Vectors--ICML 2024},
  author={Tan, Daniel and Chanin, David and Lynch, Aengus and Kanoulas, Dimitrios and Paige, Brooks and Garriga-Alonso, Adria and Kirk, Robert},
  journal={arXiv e-prints},
  pages={arXiv--2407},
  year={2024}
}

@online{dataset_debugging_with_SAEs,
  author = {Smith, Lewis and Rajamanoaran, Senthooran and Conmy, Arthur and McDougall, Callum and Lieberum, Tom and Kramar, Janos and Shah, Rohin and Nanda, Neel},
  title = {Negative Results for SAEs On Downstream Tasks and Deprioritising SAE Research},
  year = 2025,
  howpublished = {\url{https://www.lesswrong.com/posts/4uXCAJNuPKtKBsi28/sae-progress-update-2-draft#Dataset_debugging_with_SAEs}},
  urldate = {2025-06-06}
}

@inproceedings{caa,
  title={Steering Llama 2 via Contrastive Activation Addition},
  author={Rimsky, Nina and Gabrieli, Nick and Schulz, Julian and Tong, Meg and Hubinger, Evan and Turner, Alexander},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={15504--15522},
  year={2024}
}

@article{reft,
  title={Reft: Representation finetuning for language models},
  author={Wu, Zhengxuan and Arora, Aryaman and Wang, Zheng and Geiger, Atticus and Jurafsky, Dan and Manning, Christopher D and Potts, Christopher},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={63908--63962},
  year={2024}
}

@inproceedings{mwe,
  title={Discovering language model behaviors with model-written evaluations},
  author={Perez, Ethan and Ringer, Sam and Lukosiute, Kamile and Nguyen, Karina and Chen, Edwin and Heiner, Scott and Pettit, Craig and Olsson, Catherine and Kundu, Sandipan and Kadavath, Saurav and others},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
  pages={13387--13434},
  year={2023}
}

@inproceedings{steering-clear,
  title={Steering Clear: A Systematic Study of Activation Steering in a Toy Setup},
  author={Krasheninnikov, Dmitrii and Krueger, David},
  booktitle={MINT: Foundation Model Interventions},
  year={2024}
}

@article{activation-addition,
  title={Activation Addition: Steering Language Models Without Optimization},
  author={Turner, Alexander Matt and Thiergart, Lisa and Udell, David and Leech, Gavin and Mini, Ulisse and MacDiarmid, Monte},
  journal={CoRR},
  year={2023}
}

@article{ace,
  title={Refusal in LLMs is an Affine Function},
  author={Marshall, Thomas and Scherlis, Adam and Belrose, Nora},
  journal={CoRR},
  year={2024}
}

@inproceedings{lora,
  title={LoRA: Low-Rank Adaptation of Large Language Models},
  author={Hu, Edward J and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@inproceedings{dora,
  title={Dora: Weight-decomposed low-rank adaptation},
  author={Liu, Shih-Yang and Wang, Chien-Yi and Yin, Hongxu and Molchanov, Pavlo and Wang, Yu-Chiang Frank and Cheng, Kwang-Ting and Chen, Min-Hung},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@inproceedings{petl,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International conference on machine learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}

@inproceedings{dii,
  title={Finding alignments between interpretable causal variables and distributed neural representations},
  author={Geiger, Atticus and Wu, Zhengxuan and Potts, Christopher and Icard, Thomas and Goodman, Noah},
  booktitle={Causal Learning and Reasoning},
  pages={160--187},
  year={2024},
  organization={PMLR}
}

@article{transformers,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{turner2023,
  title={An introduction to transformers},
  author={Turner, Richard E},
  journal={arXiv preprint arXiv:2304.10557},
  year={2023}
}

@misc{gpt4-count,
    author={Latent Space},
    title={Commoditizing the Petaflop - with George Hotz of the tiny corp},
    year={2023},
    howpublished = {\url{https://www.latent.space/p/geohot}},
    urldate={2025-07-29}
}

@misc{gemma,
    title={Gemma 3},
    howpublished = {\url{https://goo.gle/Gemma3Report}},
    publisher={Kaggle},
    author={Gemma-Team},
    year={2025}
}

@inproceedings{linear-attention,
  title={Transformers are rnns: Fast autoregressive transformers with linear attention},
  author={Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, Fran{\c{c}}ois},
  booktitle={International conference on machine learning},
  pages={5156--5165},
  year={2020},
  organization={PMLR}
}

@article{bigbird,
  title={Big bird: Transformers for longer sequences},
  author={Zaheer, Manzil and Guruganesh, Guru and Dubey, Kumar Avinava and Ainslie, Joshua and Alberti, Chris and Ontanon, Santiago and Pham, Philip and Ravula, Anirudh and Wang, Qifan and Yang, Li and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={17283--17297},
  year={2020}
}

@article{linformer,
  title={Linformer: Self-attention with linear complexity},
  author={Wang, Sinong and Li, Belinda Z and Khabsa, Madian and Fang, Han and Ma, Hao},
  journal={arXiv preprint arXiv:2006.04768},
  year={2020}
}

@misc{sae-orig,
    title={[Interim research report] Taking features out of superposition with sparse autoencoders},
    howpublished = {\url{https://www.alignmentforum.org/posts/z6QQJbtpkEAX3Aojj/interim-research-report-taking-features-out-of-superposition}},
    publisher={Alignment Forum},
    author={Sharkey, Lee and Braun, Dan and Millidge Beren},
    year={2022}
}

@article{saes,
  title={Sparse autoencoders find highly interpretable features in language models},
  author={Cunningham, Hoagy and Ewart, Aidan and Riggs, Logan and Huben, Robert and Sharkey, Lee},
  journal={arXiv preprint arXiv:2309.08600},
  year={2023}
}

@misc{saelens,
   title = {SAELens},
   author = {Bloom, Joseph and Tigges, Curt and Duong, Anthony and Chanin, David},
   year = {2024},
   howpublished = {\url{https://github.com/jbloomAus/SAELens}}
}

@article{polysemanticity,
  title={Zoom in: An introduction to circuits},
  author={Olah, Chris and Cammarata, Nick and Schubert, Ludwig and Goh, Gabriel and Petrov, Michael and Carter, Shan},
  journal={Distill},
  volume={5},
  number={3},
  pages={e00024--001},
  year={2020}
}

@article{superposition,
  title={Toy models of superposition},
  author={Elhage, Nelson and Hume, Tristan and Olsson, Catherine and Schiefer, Nicholas and Henighan, Tom and Kravec, Shauna and Hatfield-Dodds, Zac and Lasenby, Robert and Drain, Dawn and Chen, Carol and others},
  journal={arXiv preprint arXiv:2209.10652},
  year={2022}
}

@article{sparse-coding,
  title={Sparse coding with an overcomplete basis set: A strategy employed by V1?},
  author={Olshausen, Bruno A and Field, David J},
  journal={Vision research},
  volume={37},
  number={23},
  pages={3311--3325},
  year={1997},
  publisher={Elsevier}
}

@misc{mech-interp,
    title={A Comprehensive Mechanistic Interpretability Explainer \& Glossary},
    author={Neel Nanda},
    howpublished = {\url{https://www.neelnanda.io/mechanistic-interpretability/glossary}},
    year={2021}
}


@article{k-sparsity,
  title={k-Sparse Autoencoders},
  author={Makhzani, Alireza and Frey, Brendan},
  journal={arXiv preprint arXiv:1312.5663},
  year={2013}
}

@inproceedings{saes-bad,
  title={Are Sparse Autoencoders Useful? A Case Study in Sparse Probing},
  author={Kantamneni, Subhash and Engels, Joshua and Rajamanoharan, Senthooran and Tegmark, Max and Nanda, Neel},
  booktitle={Forty-second International Conference on Machine Learning},
  year={2025}
}

@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{layernorm,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@article{adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{icv,
  title={In-context Vectors: Making In Context Learning More Effective and Controllable Through Latent Space Steering},
  author={Liu, Sheng and Ye, Haotian and Xing, Lei and Zou, James Y},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@misc{gpt-5,
  author = {Openai},
  title = {Introducing GPT 5},
  year = 2025,
  howpublished = {\url{https://openai.com/index/introducing-gpt-5/}},
  urldate = {2025-08-19}
}

@inproceedings{distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter.},
  author={Sanh, V},
  booktitle={Proceedings of Thirty-third Conference on Neural Information Processing Systems (NIPS2019)},
  year={2019}
}

@misc{icl-sae,
  author = {Kharlapenko, Dmitrii and neverix and Nanda, Neel and Conmy, Arthur},
  title = {Extracting SAE task features for in-context learning},
  year = 2024,
  howpublished = {\url{https://www.alignmentforum.org/posts/5FGXmJ3wqgGRcbyH7/extracting-sae-task-features-for-in-context-learning}},
  urldate = {2025-08-20}
}

@misc{sae-steering,
    author = {Nanda, Neel and Conmy, Arthur and smith, lewis and Rajamanoharan, Senthooran and Lieberum, Tom and Kramár, János and Varma, Vikrant},
  title = {[Full Post] Progress Update 1 from the GDM Mech Interp Team},
  year = 2024,
  howpublished = {\url{https://www.alignmentforum.org/posts/C5KAZQib3bzzpeyrg/full-post-progress-update-1-from-the-gdm-mech-interp-team}},
  urldate = {2025-08-20}
}

@article{sae-improved,
  title={Improving steering vectors by targeting sparse autoencoder features},
  author={Chalnev, Sviatoslav and Siu, Matthew and Conmy, Arthur},
  journal={arXiv preprint arXiv:2411.02193},
  year={2024}
}

@misc{c.ai,
    author = {Landymore, Frank},
  title = {Teens are forming intense relationships with ai entities, and parents have no idea},
  year = 2024,
  howpublished = {\url{https://futurism.com/the-byte/teens-relationships-ai}},
  urldate = {2025-08-26}
}

@article{psychosis,
  title={Will Generative Artificial Intelligence Chatbots Generate Delusions in Individuals Prone to Psychosis?},
  author={{\O}stergaard, S{\o}ren Dinesen},
  journal={Schizophrenia bulletin},
  volume={49},
  number={6},
  pages={1418--1419},
  year={2023}
}

@article{disempowerment,
  title={Gradual disempowerment: Systemic existential risks from incremental AI development},
  author={Kulveit, Jan and Douglas, Raymond and Ammann, Nora and Turan, Deger and Krueger, David and Duvenaud, David},
  journal={arXiv preprint arXiv:2501.16946},
  year={2025}
}

@misc{survellience,
  author = {Boffey, Daniel and Wilding, Mark},
  title = {Valuable tool or cause for alarm? Facial ID quietly becoming part of police’s arsenal},
  year = 2025,
  howpublished = {\url{https://www.theguardian.com/technology/2025/may/24/valuable-tool-or-cause-alarm-facial-id-quietly-becoming-part-police-arsenal}},
  urldate = {2025-08-26}
}

@article{deepfakes,
  title={Deepfakes: current and future trends},
  author={Gamb{\'\i}n, {\'A}ngel Fern{\'a}ndez and Yazidi, Anis and Vasilakos, Athanasios and Haugerud, H{\aa}rek and Djenouri, Youcef},
  journal={Artificial Intelligence Review},
  volume={57},
  number={3},
  pages={64},
  year={2024},
  publisher={Springer}
}

@article{agent-alignment,
  title={Scalable agent alignment via reward modeling: a research direction},
  author={Leike, Jan and Krueger, David and Everitt, Tom and Martic, Miljan and Maini, Vishal and Legg, Shane},
  journal={arXiv preprint arXiv:1811.07871},
  year={2018}
}

@article{rlhf,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{rlhf-orig,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{alignment-survey,
  title={AI Alignment: A Comprehensive Survey},
  author={Ji, Jiaming and Qiu, Tianyi and Chen, Boyuan and Zhang, Borong and Lou, Hantao and Wang, Kaile and Duan, Yawen and He, Zhonghao and Zhou, Jiayi and Zhang, Zhaowei and others},
  journal={CoRR},
  year={2023}
}

@inproceedings{misgeneralization,
  title={Goal misgeneralization in deep reinforcement learning},
  author={Di Langosco, Lauro Langosco and Koch, Jack and Sharkey, Lee D and Pfau, Jacob and Krueger, David},
  booktitle={International Conference on Machine Learning},
  pages={12004--12019},
  year={2022},
  organization={PMLR}
}

@inproceedings{peft,
  title={LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models},
  author={Hu, Zhiqiang and Wang, Lei and Lan, Yihuai and Xu, Wanyu and Lim, Ee-Peng and Bing, Lidong and Xu, Xing and Poria, Soujanya and Lee, Roy},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={5254--5276},
  year={2023}
}

@book{rl,
  title={Reinforcement Learning},
  author={Sutton, Richard S and Barto, Andrew G},
  publisher={MIT Press},
  year={1998}
}


@misc{chatgpt,
    author={Openai},
    title={Introducing ChatGPT},
    year={2022},
    howpublished = {\url{https://openai.com/index/chatgpt/}},
    urldate={2025-08-26}
}

@article{probes,
  title={Understanding intermediate layers using linear classifier probes},
  author={Alain, Guillaume and Bengio, Yoshua},
  journal={stat},
  volume={1050},
  pages={14},
  year={2016}
}

@misc{gpt-2,
  title={Language Models are Unsupervised Multitask Learners},
  author={Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  year={2019},
  howpublished={\url{https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf}}
}

@article{llama3,
  title={The llama 3 herd of models},
  author={Grattafiori, Aaron and Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Vaughan, Alex and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{dynabench,
  title={Dynabench: Rethinking benchmarking in NLP},
  author={Kiela, Douwe and Bartolo, Max and Nie, Yixin and Kaushik, Divyansh and Geiger, Atticus and Wu, Zhengxuan and Vidgen, Bertie and Prasad, Grusha and Singh, Amanpreet and Ringshia, Pratik and others},
  journal={arXiv preprint arXiv:2104.14337},
  year={2021}
}

@article{hle,
  title={Humanity's last exam},
  author={Phan, Long and Gatti, Alice and Han, Ziwen and Li, Nathaniel and Hu, Josephina and Zhang, Hugh and Zhang, Chen Bo Calvin and Shaaban, Mohamed and Ling, John and Shi, Sean and others},
  journal={arXiv preprint arXiv:2501.14249},
  year={2025}
}

@misc{grok-4,
  author = {xAI},
  title = {Grok 4},
  year = 2025,
  howpublished = {\url{x.ai/news/grok-4}},
  urldate = {2025-08-31}
}

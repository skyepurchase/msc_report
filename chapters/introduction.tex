\chapter{Introduction}
\label{ch:introduction}

\emph{In this chapter an overview of the project and this report is detailed.}
\emph{This includes what the project involves as well as why this is a worthwhile project.}
\emph{The motivation for the project will be briefly discussed along with the benefits of the analysis carried out.}

\emph{Related work to this project, including projects which precede this one and projects which cover separate but related issues, is presented.}
\emph{The differences between this project and the related work is explained.}

\emph{Finally the contributions which this project make to the field are detailed.}
\emph{This contributions are justified during the results chapter \Sref{ch:results} and reiterated in the conclusion chapter \Sref{ch:conclusion}.}

\section{Motivation}

\subsection{Benefits of Steering Vectors}

\section{Research Questions}

\section{Compute Environment}

The project was written and programmed on my personal laptop.
This is a Dell Inspiron 15'' laptop running Arch linux and i3 window manager.
The laptop has 16GB of memory with an 8 core Intel 13$^{th}$ generation i7 processor.

Preliminary tests of the experiments run in this project were done on this laptop.
However, the official results were run on \href{https://www.runpod.io/}{RunPod}, which provides a suite of possible GPU environments.
For all the results presented in \Sref{ch:results} the RTX 2000 Ada environment was used.
This environment includes a single RTX 2000 Ada GPU with 16GB of VRAM, 31GB of RAM, and 6 virtual CPUs.
The cost to run this enivornment was \$0.24 per hour.
The funding for the compute environment was provided by my supervisor through the ML Alignment and Theory Scholarship \citep{mats} which he is part of.

Occasional use of the free \href{https://colab.research.google.com/}{Google Colab} environment was used to verify the experiments ran at scale.
No results presented in this report were generated from these runs.

\section{Generative AI Disclosure}

This project aims to steer generative AI models (genAI) such as GPT 2 \citep{gpt-2} and thus genAI was used in generating the raw results presented in \Sref{ch:results}.

However, outside of the direct prompting of agents to analyse the steering adaptors presented in \Sref{ch:background}, no generative AI was used throughout the project or report.
There are two exceptions:
\begin{itemize}[nolistsep]
    \item Generating a dataset of prompt-completion templates detailed in \Sref{sec:pp-dataset}.
    \item Generating a random point cloud in Tikz for \Fref{fig:caa}.
\end{itemize}

Spellcheck was performed by Neovim and its built in spellchecker with no use of AI tools such as Grammarly.
All citations were found and generated through Google Scholar.
Assistance for Tikz diagrams was found through \href{https://www.tikz.dev}{https://www.tikz.dev}.

However, with the proliferation of AI in search engines it is not possible to state that genAI did not influence any of the \LaTeX or code snippets.
I endeavoured to not use genAI as much as possible throughout the last 3 months.

\section{Related Work}

\smalltitle{\citet{steering-clear}}
aim to analyse steering in a toy environment where they are able to control the representation density within the model.
They compare a range of steering techniques \citep{caa, reft, mimic} against each other in a controlled setting to evaluate the benefits and drawbacks of each approach.
Inspired by LoReFT \citep{reft} they introduce their own technique LoReST and demonstrate competitive performance to the other techniques.

This project reproduces a sample of plots from Figure 1 using the same toy setup described in \Sref{sec:steering-clear}.
In addition to the techniques used in the original paper the reproduction also analyses the behaviour of \citet{ace}.

This project aims to expand the analysis carried out by \citet{steering-clear} to reproduce the same effects in large language model systems.
Additionally, the relationship between the negative and positive training examples is analysed to gain a better insight as to when steering approaches fail.

\smalltitle{\citet{steerability}}
aim to analyse the generalisation of steering vectors across a range of steering datasets.
They analyse the variability of success and introduce the notion of steerability.
Using this notion they demonstrate that many techniques fail to generalise on certain datasets both in and out of distribution.

The analysis is limited to only contrastive activation addition \citep{caa} which \citet{steering-clear} show is not necessarily the ideal candidate.
Building on their work this project aims to analyse a larger range of techniques sampled from \citet{steering-clear}.
Furthermore, the properties of training datasets is analysed in more depth to determine which properties cause steering techniques to fail.

Rather than use model written evaluations \citep{mwe} a new set of steering datasets is generated with more fine grain control.
The construction of these datasets is described in \Sref{sec:prompt-pairs}.

\smalltitle{\citet{steering-taxonomy}}
present a full taxonomy of current steering vector approaches (more generally \emph{representation engineering}).
The approaches include those in \citet{steering-clear}, however, it is impractical to expand the experiments to all the approaches described due to time constraints.

The paper covers a range of topics within representation engineering that have been carried out by the community.
These focus on the types of adaptors used, the prompting framework, linear vs. non-linear adaptors, the concepts that are steered, etc.
This project continues these comparisons by analysing the effect of the dataset and number of steering examples used in the large language model setting.

\smalltitle{Sparse autoencoders as steering vectors}
There are multiple papers that utilise sparse autoencoders (SAEs) as steering vectors \citep{sae-improved, sae-steering, icl-sae}.
These approaches utilise the fact that SAEs decode high level concepts from the models intermediate representation.
This can be used to manipulate the representation towards a target concept.

Rather than utilising SAEs to steer the model this project uses the SAE features to evaluate models on free form prompts.
The SAE features provide a metric to evaluate how well the models internal representation has been effectively steered.
SAEs are explained in \Sref{sec:sae} and their use in the project is described in \Sref{sec:prompt-pairs}.

\section{Contributions}
\label{sec:contributions}

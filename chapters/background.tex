\chapter{Background}

\section{Notation}

\section{Model Alignment}

\section{Model Intervention}

\subsection{Contrastive Activation Addition}

An intuitative approach to model intervention is to perturb the model's activations in a desired direction.
By calculating a linear direction in activation space from undesired activations towards desired ones this vector can simply be added to all activations in the model during inference.
The hope is that the model produces output that matches the desired behaviour whilst maintaining the context of the new input.

\textcolor{red}{Add a figure demonstrating this!}

In the simplest form consider two example inputs with desired and undesired behaviour\footnote{assuming some level of similarity between the examples}.
Their difference gives a direction in feature space that corresponds to shifting the models output from undesired behaviour towards desired behaviour.
This is the approach proposed by \citet{activation-addition}, however, it is not robust and relies heavily on the example inputs.

To improve on this approach \citet{caa} suggest using a collection of examples and calculating their mean difference in activation space.
This requires the notion of \textit{contrastive pairs}, two inputs that are similar in all ways except for the behaviour that is being changed.
Hence, this approach is known as \textit{contrastive activation addition} (CAA).

Formally, given a set of positive example activations $(\va_i^+)_{i\le n}$ and negative example activations $(\va_i^-)_{i\le n}$ a \textit{steering vector} for this behaviour is
\[\vv_{steer} = \frac{1}{n}\sum_{i=1}^{n}\va_i^+ - \va_i^-.\]

Given a steering vector, $\vv_{steer}$, and a model activation during inference, $\va$, the resulting steered activation is
\[\va_{steered} = \va + \lambda\vv_{steer}\]
where $\lambda$ is a user-defined parameter controlling the strength of the steering intervention.
The model activation is replaced by the steered activation during inference resulting in the model producing an output aligned with the positive examples.

This approach has a few drawbacks \cite{steerability, ACE, non-linear-features} due to its assumptions.
This approach assumes that the zero-vector in activation space has the inherent meaning of no-behaviour which \citet{ACE} dispute.
Furthermore, \citet{steerability} demonstrate that this approach is not robust across behaviours that may be steered along.
The approach assumes that concepts in activation space are linear which \citet{non-linear-features} show is not universal.
Techniques such as affine concept editting (ACE) \ref{ace} use an affine approach to overcome these drawbacks.

\subsection{Affine Concept Editting}
\label{ace}

\subsection{Low-rank Representation Finetuning}
\label{loreft}

\subsection{Low-rank Representation Steering}
\label{lorest}

\section{Large Language Models}

\subsection{Transformers}

\section{Sparse Auto-Encoders}

\chapter{Methodology}

\section{Steering Clear Environment}
\label{steering-clear}

The setup of this environment follows \cite{steering-clear}.
The model to steer is a 4-layer multi-layer perceptron (MLP) with residual connections \cite{resnet} across all layers.
After the MLP, a layernorm \cite{layernorm} and single layer classifier is added.
All non-linearity throughout the model is gaussian error linear unit (GeLU).
The hidden layers follow 512-512-256-512 architecture regardless of dataset specifics.

\subsection{Dataset}
\label{steering-clear:dataset}

To control the behaviour of model and the steering approaches a synthetic dataset is used.
Each dataset sample consists of $m$ ``attributes" which can take 8 possible discrete values.
Each discrete value is represented by an ``anchor'' vector $\vmu_i \in \mathbb{R}^8, i \in \{1,8\}$ sampled from a gaussian distribution $\mathcal{N}(\vzero, 1)$.
To simulate real-world conditions gaussian noise is added to the samples from $\mathcal{N}(\vzero, 0.1)$.
This does mean the values are generally highly seperable.

The dataset comprises of $n$ input-output vectors where the input vector is the concatenation of $m$ 8-dimensional vectors.
Thus, an input vector has length $8m$ and the target vector has length $m$.
\citet{steering-clear} carry out a range of experiments for $m \in \{60, 90, 120\}$ but always use 8 values represented by 8 dimensional vectors.
They take a sample of $2,000,000$ i.i.d samples but due to memory constraints only $500,000$ are used in this project.
No test set is used in either however an 80:20 split for training and validation set is used for identifying the best performing model.

\subsection{Pre-training}

The MLP model is trained on the $500,000$ training samples for 50 epochs using Adam \cite{adam} with a learning rate of $0.001$.
As per \citet{steering-clear} a cross entropy loss is used to train the model.
The model that achieves the best validation loss is saved and used for the steering task.

Regardless of exact epochs, learning rate or optimiser the best performing model should achieve close to $100\%$.
Models used for the presented results achieved $\sim 99\%$.

\subsection{Steering Task}

The task is to successfully steer a model to always predict a specific value for a specific attribute.
For example, the goal would be steer attribute $3$ towards value $\vmu_1$.
\citet{steering-clear} carry out three experiments to steer one, two or three attributes simultaneously.
Instead, this reproduction will focus on steering only one attribute at a time.

As the attribute anchors are generated randomly there is no dataset bias towards any particular value.
For this reason all attributes are steered towards value $\vmu_1$.

In addition to the dataset generate, $4096$ are generated as a training set for the steering approaches and a further $1000$ are generated as a test set.
This is repeated 20 times to get an average metric across steering approaches.

For each adaptor a range of hyperparameters is used to analyse the effect on steering performance.
The number of steering examples is also varied from $4$ up to $4096$ increasing in powers of $2$.
\citet{steering-clear} use this to analyse the representation densities effect of required number of examples.

\smalltitle{Steering metric.} As the model was trained to predict discrete attribute labels and the steering adaptor simply aims for a specific attribute value it is possible to use the models accuracy on the target attributes.
\citet{steering-clear} use the full target output label, however, this was found to be dominated by unsteered attributes.
Instead the accuracy on only the steered attribute is used.

\section{Prompt Pairs Environment}
\label{prompt-pairs}

\citet{steering-clear} aim to analyse the effects of model feature density and the number of steering examples.
To achieve this the set up a toy environment with synthetic data and a small, controllable model.
To analyse similar effects, as well as the effects of the steering dataset, in a situation closer to real-world use requires utilising real-world models.

As only LLMs are considered this means the dataset is made of natural language prompts.
Positive and negative activations are sampled from the target layer and the last token.
Generally, the two prompts used to extract positive and negative activations are identical except for the last token \cite{steerability, icv, activation-addition, rep-engineering}.

\subsection{dataset}

Rather than generate thousands of entirely unique pairs of prompts a smaller set of templates with adjustable ``contexts'' and ``targets'' is used.
And example template would be:

\texttt{Everyone thought <context> would lose. In the end they <target>}.

Then a range of relevant contexts (such as \texttt{the dancer} or \texttt{the driver}) and targets (such as \texttt{won} or \texttt{lost}) can be used.
A standard prompt pair is therefore two prompts who's templates and contexts are identical but who's targets are in opposition.
As the target is the last word activations can be extracted to steer the model from the negative target to the positive target.

Unlike the model written evaluations \cite{mwe} dataset used in \citet{steerability} this dataset does not use multiple choice questions and instead a small range of target values.
This allows the model to produce more tokens than just ``yes'', ``no'' or ``A'', ``B''.
This also allows for more control, such as changing context between positive and negative pairs or using ``random'' negative targets and meaningful positive targets.
Note that all targets are \emph{a single word} or ideally token to simplify the steering process.

Rather than a single dataset of this form multiple datasets are generated that cover a range of contexts and behaviours.
They are aimed to be useful real-world situations however they are still fabricated and so are not a perfect representation.
To generate the large number of templates, contexts and targets a set of example sentences were generated by GPT-5 \cite{gpt-5} and adjusted to extract templates, contexts and targets.

The full list of templates, contexts and targets are presented in \Sref{app:prompt-pairs}.

\subsection{Steering Task}

The goal is to steer the model from generating the negative targets to generating the positive targets.
As the negative and positive targets have many potential options it is possible the model does not produce the exact same positive target word, however, getting the correct semantic meaning is the aim.

For each of the datasets, after activation extraction, 100 are separated for testing and the rest used for adaptor traing/initialisation.
Similar to \cite{steering-clear}, a range of example pairs are used ranging from 4 example pairs to 1024 example pairs.
The same range of adaptor hyperparameters are used to roughly compare the toy experiment to real-world scenarios.
The experiments are also run without any adaptor to get a baseline value to compare from.
\textcolor{red}{MIGHT BE WORTH DOING INDIVIDUAL DATASETS.}
All steering metrics are averaged over the range of datasets to get an average efficacy across the datasets.

\smalltitle{Steering metrics.} Unlike the steering clear environment \Sref{steering-clear}, it is hard to quantify accuracy on the steered attribute.
Instead 3 metrics are used to evaluate the success of the steering approach.

Two are based on the SAE, \Sref{sec:sae}, features of the final, target token of the model at the target layer:
\begin{enumerate}[nolistsep]
    \item During activation extraction, the SAE features that are consistently activated on the final token across all \emph{positive} examples are identified.
        The average activation of these features during training is used to evaluate how well the steering adaptor is increasing the models representation of the target behaviour.
    \item A random selection of SAE features that were consistently not activated for \emph{both} examples during activation extraction are considered test features.
        The average activation of the test features during training is used to evaluate how well the adaptor effects only the target features.
\end{enumerate}
Together these provide insight into how well the adaptor steers the internal model representations towards the intended behaviour.

To gather information about how well the adaptors effect the output the semantic similarity of the generated model token and the target model token is used.
Using distilbert \cite{distilbert} as a semantic embedding of words the average cosine similarity between generated word and target word across the test examples is used.

Each metric on its own is useful but can be prone to biases that the other metrics highlight.
A more complete picture of how the adaptors and models behaved can be achieved by analysing all three metrics together.

\section{Prompting LLMs}
